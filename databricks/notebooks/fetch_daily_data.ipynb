{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98631fb5-c4b4-49ce-9e7c-f02ecb0b02eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Request Raw Data from TMDB API\n",
    "\n",
    "### Description\n",
    "This process involves calling the top 40 most popular movies at the time from the TMDB API. The response is then parsed and loaded into an Azure Data Lake Storage (ADLS) Gen2 account as raw data.\n",
    "\n",
    "### Requirements\n",
    "which have already been handled by my Terraform code:\n",
    "\n",
    "- Libraries installed\n",
    "- Mount point to the storage account\n",
    "- TMDB API key added in Databricks Secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96937cf8-a19d-422d-8fc4-23aebf6302b2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9ded14-c644-4213-8786-bb3ac54b486f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "current_date = datetime.date.today()\n",
    "fm_current_date = current_date.strftime('%d-%m-%Y')\n",
    "base_path = '/mnt/movrec-container/raw' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "020847da-74fd-490f-80f0-00bc6a92192c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_movie_data(page):\n",
    "    TMDB_KEY = dbutils.secrets.get(scope=\"application\", key=\"tmdb_api_key\")\n",
    "    url = \"https://api.themoviedb.org/3/discover/movie\"\n",
    "    params = {\n",
    "        \"include_adult\": \"true\",\n",
    "        \"include_video\": \"false\",\n",
    "        \"language\": \"en-US\",\n",
    "        \"page\": page,\n",
    "        \"sort_by\": \"popularity.desc\",\n",
    "    }\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {TMDB_KEY}\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b75698ce-561b-4f7a-b1af-a72ef9b23cb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pages_to_fetch = [1, 2]\n",
    "dataframes = [pd.DataFrame(fetch_movie_data(page)) for page in pages_to_fetch]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "merged_df['date'] = fm_current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26446f4b-dc15-4a0a-8f0a-a8c8c54cd26f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "path= os.path.join(base_path, str(current_date.year), str(current_date.month))\n",
    "try:\n",
    "    dbutils.fs.ls(path)\n",
    "except Exception as e:\n",
    "    dbutils.fs.mkdirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42ffec5e-d1a7-4012-b7b1-e955e7ec2fea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Notice when work with dbfs files\n",
    "- **/dbfs** is ONLY and MUST accepted when specify WRITE path \n",
    "- **dbfs:** is legal format in databricks when work with dbfs files, but it is optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a7894cc-962a-4248-84c2-18242be3c8d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.10/site-packages/pyarrow/pandas_compat.py:358: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if _pandas_api.is_sparse(col):\n"
     ]
    }
   ],
   "source": [
    "merged_df.to_parquet(f\"/dbfs{path}/{fm_current_date}.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "fetch_daily_data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
